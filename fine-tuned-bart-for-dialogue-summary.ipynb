{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This notebook presents a comprehensive guide to fine-tuning Facebook's BART (Bidirectional and Auto-Regressive Transformers) model for the task of summarizing chat conversations. \n",
    "\n",
    "The notebook is structured to provide a seamless and educative experience in applying advanced NLP techniques for practical applications.\n",
    "\n",
    "The model fine-tuning utilizes three distinct datasets:\n",
    "\n",
    "1. **DialogSum Dataset:** A specialized dataset for dialogue summarization, offering diverse conversational examples.\n",
    "\n",
    "2. **SAMSUM Dataset by Samsung:** This dataset comprises scripted chat conversations with associated human-written summaries, providing a rich ground for training and validating summarization models.\n",
    "\n",
    "3. **Custom Dataset:** A personally curated dataset, designed to include a variety of chat styles and topics, ensuring robustness and versatility in the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/0k89l9jx68d6z4q8vwn0zxc80000gn/T/ipykernel_7970/3470007018.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install rogue score to evaluate the summaries generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DialogSum dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to read and clean the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "- To enhance the model's applicability to real-world scenarios, the original DialogSum dataset was modified by replacing generic placeholders 'Person1' and 'Person2' with a diverse list of names. \n",
    "- This adaptation ensures that the model is trained on data more representative of actual conversation patterns, thereby improving its practical utility and performance in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read JSONL files and convert them to pandas DataFrame\n",
    "def read_jsonl_to_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and converts it into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the JSONL file to be read.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to replace placeholder names in the DataFrame with random names from a list\n",
    "def replace_names(df, names_list):\n",
    "    \"\"\"\n",
    "    Replaces placeholders with random names from the names_list in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame where names need to be replaced.\n",
    "    names_list (list): List of names to be used for replacement.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Updated DataFrame with names replaced.\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        # Randomly select two names\n",
    "        name1, name2 = random.sample(names_list, 2)\n",
    "\n",
    "        # Replace placeholders in dialogue and summary\n",
    "        df.at[index, 'dialogue'] = row['dialogue'].replace('#Person1#', name1).replace('#Person2#', name2)\n",
    "        df.at[index, 'summary'] = row['summary'].replace('#Person1#', name1).replace('#Person2#', name2)\n",
    "        \n",
    "    # Clean up the DataFrame by dropping unnecessary columns and duplicates\n",
    "    df.drop(columns = ['fname', 'topic'], inplace = True)\n",
    "    df.dropna(inplace = True, axis = 1)\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    return df\n",
    "\n",
    "# List of names to be used for replacement\n",
    "names_list = [\n",
    "    'Alice', 'Bob', 'Charlie', 'Diana', 'Edward', 'Fiona', 'George', 'Hannah', 'Ian', 'Julia', 'Kevin', 'Laura',\n",
    "    'Megan', 'Nathan', 'Olivia', 'Peter', 'Quincy', 'Rachel', 'Samuel', 'Tina', 'Umar', 'Violet', 'William', 'Xena',\n",
    "    'Yasmin', 'Zachary', 'Amelia', 'Brian', 'Carmen', 'David', 'Elena', 'Frank', 'Grace', 'Henry', 'Isla', 'Jack',\n",
    "    'Kara', 'Leo', 'Maya', 'Nolan', 'Ophelia', 'Pablo', 'Queenie', 'Raj', 'Sara', 'Tom', 'Ursula', 'Victor', 'Wendy',\n",
    "    'Xander', 'Yolanda', 'Zane', 'Anita', 'Blake', 'Claire', 'Derek', 'Eve', 'Felix', 'Giselle', 'Harold', 'Ivy', 'Jasper', 'Kylie', 'Liam', 'Monica', 'Nigel', 'Opal', 'Preston', 'Quinn',\n",
    "    'Rosa', 'Sebastian', 'Tracy', 'Ulysses', 'Valerie', 'Winston', 'Xiomara', 'Yvette', 'Zelda', 'Aaron', 'Brianna',\n",
    "    'Cody', 'Danielle', 'Ethan', 'Farrah', 'Gavin', 'Hazel', 'Isaac', 'Jocelyn', 'Kyle', 'Luna', 'Miles', 'Nadia',\n",
    "    'Orlando', 'Penelope', 'Quincy', 'Rebecca', 'Shane', 'Tara', 'Ursula', 'Vance', 'Whitney', 'Xavier', 'Yasmine',\n",
    "    'Zach', 'Aurora', 'Brandon', 'Celeste'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set of DialogSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valerie: Hi, Mr. Smith. I'm Doctor Hawkins. Wh...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Queenie: Hello Mrs. Parker, how have you been?...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elena: Excuse me, did you see a set of keys?\\n...</td>\n",
       "      <td>Elena's looking for a set of keys and asks for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hazel: Why didn't you tell me you had a girlfr...</td>\n",
       "      <td>Hazel's angry because Monica didn't tell Hazel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ursula: Watsup, ladies! Y'll looking'fine toni...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>Ethan: Excuse me. You are Mr. Green from Manch...</td>\n",
       "      <td>Tan Ling picks Mr. Green up who is easily reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>Victor: Mister Ewing said we should show up at...</td>\n",
       "      <td>Victor and Fiona plan to take the underground ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12457</th>\n",
       "      <td>Ulysses: How can I help you today?\\nKara: I wo...</td>\n",
       "      <td>Kara rents a small car for 5 days with the hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12458</th>\n",
       "      <td>Umar: You look a bit unhappy today. What's up?...</td>\n",
       "      <td>Celeste's mom lost her job. Celeste hopes mom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>Whitney: Mom, I'm flying to visit uncle Lee's ...</td>\n",
       "      <td>Whitney asks for Yasmine's idea of packing the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dialogue  \\\n",
       "0      Valerie: Hi, Mr. Smith. I'm Doctor Hawkins. Wh...   \n",
       "1      Queenie: Hello Mrs. Parker, how have you been?...   \n",
       "2      Elena: Excuse me, did you see a set of keys?\\n...   \n",
       "3      Hazel: Why didn't you tell me you had a girlfr...   \n",
       "4      Ursula: Watsup, ladies! Y'll looking'fine toni...   \n",
       "...                                                  ...   \n",
       "12455  Ethan: Excuse me. You are Mr. Green from Manch...   \n",
       "12456  Victor: Mister Ewing said we should show up at...   \n",
       "12457  Ulysses: How can I help you today?\\nKara: I wo...   \n",
       "12458  Umar: You look a bit unhappy today. What's up?...   \n",
       "12459  Whitney: Mom, I'm flying to visit uncle Lee's ...   \n",
       "\n",
       "                                                 summary  \n",
       "0      Mr. Smith's getting a check-up, and Doctor Haw...  \n",
       "1      Mrs Parker takes Ricky for his vaccines. Dr. P...  \n",
       "2      Elena's looking for a set of keys and asks for...  \n",
       "3      Hazel's angry because Monica didn't tell Hazel...  \n",
       "4      Malik invites Nikki to dance. Nikki agrees if ...  \n",
       "...                                                  ...  \n",
       "12455  Tan Ling picks Mr. Green up who is easily reco...  \n",
       "12456  Victor and Fiona plan to take the underground ...  \n",
       "12457  Kara rents a small car for 5 days with the hel...  \n",
       "12458  Celeste's mom lost her job. Celeste hopes mom ...  \n",
       "12459  Whitney asks for Yasmine's idea of packing the...  \n",
       "\n",
       "[12460 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to JSONL file\n",
    "train_file_path = 'dialogsum.train.jsonl'\n",
    "\n",
    "# Reading the JSONL file and creating a DataFrame\n",
    "train_df1 = read_jsonl_to_dataframe(train_file_path)\n",
    "\n",
    "# Replacing names in the DataFrame\n",
    "train_df1 = replace_names(train_df1, names_list)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame with replaced names\n",
    "train_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set of DialogSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zane: Hello, how are you doing today?\\nUlysses...</td>\n",
       "      <td>Ulysses has trouble breathing. The doctor asks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liam: Hey Jimmy. Let's go workout later today....</td>\n",
       "      <td>Liam invites Jimmy to go workout and persuades...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luna: I need to stop eating such unhealthy foo...</td>\n",
       "      <td>Luna plans to stop eating unhealthy foods, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zane: Do you believe in UFOs?\\nClaire: Of cour...</td>\n",
       "      <td>Claire believes in UFOs and can see them in dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob: Did you go to school today?\\nRebecca: Of ...</td>\n",
       "      <td>Bob didn't go to school today. Rebecca wants t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Megan: Now that it's the new year, I've decide...</td>\n",
       "      <td>Megan decides to stop smoking and come out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Frank: You married Joe, didn't you? \\nKara: Jo...</td>\n",
       "      <td>Frank thought Kara married Joe. Kara denies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Victor: How can I help you mam?\\nGeorge: I was...</td>\n",
       "      <td>George's car makes noises. Victor thinks it ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Pablo: Hello, Amazon's customer service. How c...</td>\n",
       "      <td>Kara calls Amazon's customer service because o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Zachary: I can't believe it's almost summer.\\n...</td>\n",
       "      <td>Maya tells Zachary Maya is going to work for a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialogue  \\\n",
       "0    Zane: Hello, how are you doing today?\\nUlysses...   \n",
       "1    Liam: Hey Jimmy. Let's go workout later today....   \n",
       "2    Luna: I need to stop eating such unhealthy foo...   \n",
       "3    Zane: Do you believe in UFOs?\\nClaire: Of cour...   \n",
       "4    Bob: Did you go to school today?\\nRebecca: Of ...   \n",
       "..                                                 ...   \n",
       "495  Megan: Now that it's the new year, I've decide...   \n",
       "496  Frank: You married Joe, didn't you? \\nKara: Jo...   \n",
       "497  Victor: How can I help you mam?\\nGeorge: I was...   \n",
       "498  Pablo: Hello, Amazon's customer service. How c...   \n",
       "499  Zachary: I can't believe it's almost summer.\\n...   \n",
       "\n",
       "                                               summary  \n",
       "0    Ulysses has trouble breathing. The doctor asks...  \n",
       "1    Liam invites Jimmy to go workout and persuades...  \n",
       "2    Luna plans to stop eating unhealthy foods, and...  \n",
       "3    Claire believes in UFOs and can see them in dr...  \n",
       "4    Bob didn't go to school today. Rebecca wants t...  \n",
       "..                                                 ...  \n",
       "495  Megan decides to stop smoking and come out of ...  \n",
       "496       Frank thought Kara married Joe. Kara denies.  \n",
       "497  George's car makes noises. Victor thinks it ne...  \n",
       "498  Kara calls Amazon's customer service because o...  \n",
       "499  Maya tells Zachary Maya is going to work for a...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your JSONL file\n",
    "valid_file_path = 'dialogsum.dev.jsonl'\n",
    "\n",
    "# Read JSONL file and create DataFrame\n",
    "valid_df1 = read_jsonl_to_dataframe(valid_file_path)\n",
    "\n",
    "# Replace names in the DataFrame\n",
    "valid_df1 = replace_names(valid_df1, names_list)\n",
    "\n",
    "# Display the first few rows of the DataFrame with replaced names\n",
    "valid_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set of DialogSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.370918Z",
     "iopub.status.busy": "2023-11-16T16:24:15.370601Z",
     "iopub.status.idle": "2023-11-16T16:24:15.409873Z",
     "shell.execute_reply": "2023-11-16T16:24:15.408951Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.370882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary1</th>\n",
       "      <th>topic1</th>\n",
       "      <th>summary2</th>\n",
       "      <th>topic2</th>\n",
       "      <th>summary3</th>\n",
       "      <th>topic3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>communication method</td>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>company policy</td>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>dictation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: You're finally here! What took so l...</td>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>public transportation</td>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>transportation</td>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>discuss transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: Kate, you never believe what's happ...</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>divorce</td>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>divorce</td>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>discuss divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: Happy Birthday, this is for you, Br...</td>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>birthday party</td>\n",
       "      <td>#Person1# attends Brian's birthday party. Bria...</td>\n",
       "      <td>birthday party</td>\n",
       "      <td>#Person1# has a dance with Brian at Brian's bi...</td>\n",
       "      <td>birthday party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: This Olympic park is so big!\\n#Pers...</td>\n",
       "      <td>#Person1# is surprised at the Olympic Stadium'...</td>\n",
       "      <td>Olympic Stadium</td>\n",
       "      <td>#Person2# shows #Person1# around the construct...</td>\n",
       "      <td>sports stadium</td>\n",
       "      <td>#Person2# introduces the Olympic Stadium's fin...</td>\n",
       "      <td>Olympic Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_495</td>\n",
       "      <td>#Person1#: Hey, Charlie, do you want to come t...</td>\n",
       "      <td>Jack invites Charlie to play a new video game ...</td>\n",
       "      <td>video game invitation</td>\n",
       "      <td>Jack asks Charlie to come over and play the ne...</td>\n",
       "      <td>\\n\\nentertainment activity schedule</td>\n",
       "      <td>Jack invites Charlie to play video games after...</td>\n",
       "      <td>play game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person1#: How did you get interested in count...</td>\n",
       "      <td>#Person2# explains to #Person1# about how #Per...</td>\n",
       "      <td>conversation about interest</td>\n",
       "      <td>#Person2# shares #Person2#'s career in the pas...</td>\n",
       "      <td>work experience</td>\n",
       "      <td>#Person2# tells #Person1# about #Person2#'s ow...</td>\n",
       "      <td>country music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_497</td>\n",
       "      <td>#Person1#: Excuse me, Alice, I've never used t...</td>\n",
       "      <td>Alice guides #Person1# to use the washing mach...</td>\n",
       "      <td>campus conversation</td>\n",
       "      <td>#Person1# asks Alice how to use the washing ma...</td>\n",
       "      <td>campus life conversation</td>\n",
       "      <td>#Person1# doesn't know how to use the washing ...</td>\n",
       "      <td>clothes washing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_498</td>\n",
       "      <td>#Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...</td>\n",
       "      <td>Steve is looking for a new place to live and M...</td>\n",
       "      <td>house renting</td>\n",
       "      <td>Matthew and Steve meet after a long time. Stev...</td>\n",
       "      <td>finding a house</td>\n",
       "      <td>Steve has been looking for a place to live. Ma...</td>\n",
       "      <td>find a house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>test_499</td>\n",
       "      <td>#Person1#: Hey, Betsy, did you hear the great ...</td>\n",
       "      <td>Frank invites Besty to the party to celebrate ...</td>\n",
       "      <td>party invitation</td>\n",
       "      <td>Frank invites Betsy to the big promotion party...</td>\n",
       "      <td>promotion party invitation</td>\n",
       "      <td>Frank invites Betsy to his party for his promo...</td>\n",
       "      <td>party invitation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                           dialogue  \\\n",
       "0      test_0  #Person1#: Ms. Dawson, I need you to take a di...   \n",
       "1      test_1  #Person1#: You're finally here! What took so l...   \n",
       "2      test_2  #Person1#: Kate, you never believe what's happ...   \n",
       "3      test_3  #Person1#: Happy Birthday, this is for you, Br...   \n",
       "4      test_4  #Person1#: This Olympic park is so big!\\n#Pers...   \n",
       "..        ...                                                ...   \n",
       "495  test_495  #Person1#: Hey, Charlie, do you want to come t...   \n",
       "496  test_496  #Person1#: How did you get interested in count...   \n",
       "497  test_497  #Person1#: Excuse me, Alice, I've never used t...   \n",
       "498  test_498  #Person1#: Matthew? Hi!\\n#Person2#: Steve! Hav...   \n",
       "499  test_499  #Person1#: Hey, Betsy, did you hear the great ...   \n",
       "\n",
       "                                              summary1  \\\n",
       "0    Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1    #Person2# arrives late because of traffic jam....   \n",
       "2    #Person1# tells Kate that Masha and Hero get d...   \n",
       "3    #Person1# and Brian are at the birthday party ...   \n",
       "4    #Person1# is surprised at the Olympic Stadium'...   \n",
       "..                                                 ...   \n",
       "495  Jack invites Charlie to play a new video game ...   \n",
       "496  #Person2# explains to #Person1# about how #Per...   \n",
       "497  Alice guides #Person1# to use the washing mach...   \n",
       "498  Steve is looking for a new place to live and M...   \n",
       "499  Frank invites Besty to the party to celebrate ...   \n",
       "\n",
       "                          topic1  \\\n",
       "0           communication method   \n",
       "1          public transportation   \n",
       "2                        divorce   \n",
       "3                 birthday party   \n",
       "4                Olympic Stadium   \n",
       "..                           ...   \n",
       "495        video game invitation   \n",
       "496  conversation about interest   \n",
       "497          campus conversation   \n",
       "498                house renting   \n",
       "499             party invitation   \n",
       "\n",
       "                                              summary2  \\\n",
       "0    In order to prevent employees from wasting tim...   \n",
       "1    #Person2# decides to follow #Person1#'s sugges...   \n",
       "2    #Person1# tells Kate that Masha and Hero are g...   \n",
       "3    #Person1# attends Brian's birthday party. Bria...   \n",
       "4    #Person2# shows #Person1# around the construct...   \n",
       "..                                                 ...   \n",
       "495  Jack asks Charlie to come over and play the ne...   \n",
       "496  #Person2# shares #Person2#'s career in the pas...   \n",
       "497  #Person1# asks Alice how to use the washing ma...   \n",
       "498  Matthew and Steve meet after a long time. Stev...   \n",
       "499  Frank invites Betsy to the big promotion party...   \n",
       "\n",
       "                                  topic2  \\\n",
       "0                         company policy   \n",
       "1                         transportation   \n",
       "2                                divorce   \n",
       "3                         birthday party   \n",
       "4                         sports stadium   \n",
       "..                                   ...   \n",
       "495  \\n\\nentertainment activity schedule   \n",
       "496                      work experience   \n",
       "497             campus life conversation   \n",
       "498                      finding a house   \n",
       "499           promotion party invitation   \n",
       "\n",
       "                                              summary3                  topic3  \n",
       "0    Ms. Dawson takes a dictation for #Person1# abo...               dictation  \n",
       "1    #Person2# complains to #Person1# about the tra...  discuss transportation  \n",
       "2    #Person1# and Kate talk about the divorce betw...         discuss divorce  \n",
       "3    #Person1# has a dance with Brian at Brian's bi...          birthday party  \n",
       "4    #Person2# introduces the Olympic Stadium's fin...         Olympic Stadium  \n",
       "..                                                 ...                     ...  \n",
       "495  Jack invites Charlie to play video games after...               play game  \n",
       "496  #Person2# tells #Person1# about #Person2#'s ow...           country music  \n",
       "497  #Person1# doesn't know how to use the washing ...         clothes washing  \n",
       "498  Steve has been looking for a place to live. Ma...            find a house  \n",
       "499  Frank invites Betsy to his party for his promo...        party invitation  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your JSONL file\n",
    "test_file_path = '/kaggle/input/dialogue-chat/dialogsum.test.jsonl'\n",
    "\n",
    "# Read JSONL file and create DataFrame\n",
    "test_df1 = read_jsonl_to_dataframe(test_file_path)\n",
    "\n",
    "# Replace names in the DataFrame\n",
    "# test_df = replace_names(test_df, names_list)\n",
    "\n",
    "# Display the first few rows of the DataFrame with replaced names\n",
    "test_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SAMSUM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function to clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.411278Z",
     "iopub.status.busy": "2023-11-16T16:24:15.410994Z",
     "iopub.status.idle": "2023-11-16T16:24:15.419940Z",
     "shell.execute_reply": "2023-11-16T16:24:15.419019Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.411253Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    # Count and print the number of duplicate rows in the DataFrame\n",
    "    dup = df.duplicated().sum()\n",
    "    print('Number of duplicates: ', dup)\n",
    "    \n",
    "    # If there are duplicates, remove them and print confirmation\n",
    "    if dup > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print('Duplicate values removed.')\n",
    "    \n",
    "    # Remove the 'id' column from the DataFrame\n",
    "    df.drop('id', axis=1, inplace=True)\n",
    "    \n",
    "    # Calculate and print the number of missing values in each column\n",
    "    missing = df.isna().sum()\n",
    "    print('Number of missing values: ', missing)\n",
    "    \n",
    "    # Remove rows with missing values from the DataFrame\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Return the cleaned DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.421611Z",
     "iopub.status.busy": "2023-11-16T16:24:15.421179Z",
     "iopub.status.idle": "2023-11-16T16:24:15.765997Z",
     "shell.execute_reply": "2023-11-16T16:24:15.764907Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.421572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training data from the SAMSUM dataset for chat summarization\n",
    "# This dataset is used for training the model to summarize chat conversations\n",
    "train_df2 = pd.read_json('/kaggle/input/samsum-dataset-for-chat-summarization/train.json')\n",
    "\n",
    "# Load the validation data from the SAMSUM dataset\n",
    "# Validation data is used to tune the model's hyperparameters and prevent overfitting\n",
    "valid_df2 = pd.read_json('/kaggle/input/samsum-dataset-for-chat-summarization/val.json')\n",
    "\n",
    "# Load the test data from the SAMSUM dataset\n",
    "# Test data is used for evaluating the model's performance on unseen data\n",
    "test_df2 = pd.read_json('/kaggle/input/samsum-dataset-for-chat-summarization/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning SAMSUM Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.768391Z",
     "iopub.status.busy": "2023-11-16T16:24:15.767441Z",
     "iopub.status.idle": "2023-11-16T16:24:15.820580Z",
     "shell.execute_reply": "2023-11-16T16:24:15.819687Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.768360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  0\n",
      "Number of missing values:  summary     0\n",
      "dialogue    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14727</th>\n",
       "      <td>Romeo is trying to get Greta to add him to her...</td>\n",
       "      <td>Romeo: You are on my ‘People you may know’ lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14728</th>\n",
       "      <td>Theresa is at work. She gets free food and fre...</td>\n",
       "      <td>Theresa: &lt;file_photo&gt;\\r\\nTheresa: &lt;file_photo&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14729</th>\n",
       "      <td>Japan is going to hunt whales again. Island an...</td>\n",
       "      <td>John: Every day some bad news. Japan will hunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14730</th>\n",
       "      <td>Celia couldn't make it to the afternoon with t...</td>\n",
       "      <td>Jennifer: Dear Celia! How are you doing?\\r\\nJe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14731</th>\n",
       "      <td>Georgia and Juliette are looking for a hotel i...</td>\n",
       "      <td>Georgia: are you ready for hotel hunting? We n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14732 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary  \\\n",
       "0      Amanda baked cookies and will bring Jerry some...   \n",
       "1      Olivia and Olivier are voting for liberals in ...   \n",
       "2      Kim may try the pomodoro technique recommended...   \n",
       "3      Edward thinks he is in love with Bella. Rachel...   \n",
       "4      Sam is confused, because he overheard Rick com...   \n",
       "...                                                  ...   \n",
       "14727  Romeo is trying to get Greta to add him to her...   \n",
       "14728  Theresa is at work. She gets free food and fre...   \n",
       "14729  Japan is going to hunt whales again. Island an...   \n",
       "14730  Celia couldn't make it to the afternoon with t...   \n",
       "14731  Georgia and Juliette are looking for a hotel i...   \n",
       "\n",
       "                                                dialogue  \n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...  \n",
       "1      Olivia: Who are you voting for in this electio...  \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...  \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....  \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...  \n",
       "...                                                  ...  \n",
       "14727  Romeo: You are on my ‘People you may know’ lis...  \n",
       "14728  Theresa: <file_photo>\\r\\nTheresa: <file_photo>...  \n",
       "14729  John: Every day some bad news. Japan will hunt...  \n",
       "14730  Jennifer: Dear Celia! How are you doing?\\r\\nJe...  \n",
       "14731  Georgia: are you ready for hotel hunting? We n...  \n",
       "\n",
       "[14732 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(train_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning SAMSUM Valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.824140Z",
     "iopub.status.busy": "2023-11-16T16:24:15.823831Z",
     "iopub.status.idle": "2023-11-16T16:24:15.842255Z",
     "shell.execute_reply": "2023-11-16T16:24:15.841299Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.824114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  0\n",
      "Number of missing values:  summary     0\n",
      "dialogue    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A will go to the animal shelter tomorrow to ge...</td>\n",
       "      <td>A: Hi Tom, are you busy tomorrow’s afternoon?\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emma and Rob love the advent calendar. Lauren ...</td>\n",
       "      <td>Emma: I’ve just fallen in love with this adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison is pregnant but she doesn't want to ta...</td>\n",
       "      <td>Jackie: Madison is pregnant\\r\\nJackie: but she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marla found a pair of boxers under her bed.</td>\n",
       "      <td>Marla: &lt;file_photo&gt;\\r\\nMarla: look what I foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert wants Fred to send him the address of t...</td>\n",
       "      <td>Robert: Hey give me the address of this music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Carla's date for graduation is on June 4th. Di...</td>\n",
       "      <td>Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Bev is going on the school trip with her son. ...</td>\n",
       "      <td>Gita: Hello, this is Beti's Mum Gita, I wanted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Greg cheated on Julia. He apologises to her. R...</td>\n",
       "      <td>Julia: Greg just texted me\\r\\nRobert: ugh, del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Marry broke her nail and has a party tomorrow....</td>\n",
       "      <td>Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Paige wants to have the declaration sent later...</td>\n",
       "      <td>Paige: I asked them to wait and send the decla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary  \\\n",
       "0    A will go to the animal shelter tomorrow to ge...   \n",
       "1    Emma and Rob love the advent calendar. Lauren ...   \n",
       "2    Madison is pregnant but she doesn't want to ta...   \n",
       "3          Marla found a pair of boxers under her bed.   \n",
       "4    Robert wants Fred to send him the address of t...   \n",
       "..                                                 ...   \n",
       "813  Carla's date for graduation is on June 4th. Di...   \n",
       "814  Bev is going on the school trip with her son. ...   \n",
       "815  Greg cheated on Julia. He apologises to her. R...   \n",
       "816  Marry broke her nail and has a party tomorrow....   \n",
       "817  Paige wants to have the declaration sent later...   \n",
       "\n",
       "                                              dialogue  \n",
       "0    A: Hi Tom, are you busy tomorrow’s afternoon?\\...  \n",
       "1    Emma: I’ve just fallen in love with this adven...  \n",
       "2    Jackie: Madison is pregnant\\r\\nJackie: but she...  \n",
       "3    Marla: <file_photo>\\r\\nMarla: look what I foun...  \n",
       "4    Robert: Hey give me the address of this music ...  \n",
       "..                                                 ...  \n",
       "813  Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...  \n",
       "814  Gita: Hello, this is Beti's Mum Gita, I wanted...  \n",
       "815  Julia: Greg just texted me\\r\\nRobert: ugh, del...  \n",
       "816  Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...  \n",
       "817  Paige: I asked them to wait and send the decla...  \n",
       "\n",
       "[818 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(valid_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning SAMSUM Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.843635Z",
     "iopub.status.busy": "2023-11-16T16:24:15.843351Z",
     "iopub.status.idle": "2023-11-16T16:24:15.860967Z",
     "shell.execute_reply": "2023-11-16T16:24:15.859901Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.843611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates:  0\n",
      "Number of missing values:  summary     0\n",
      "dialogue    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannah needs Betty's number but Amanda doesn't...</td>\n",
       "      <td>Hannah: Hey, do you have Betty's number?\\nAman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eric and Rob are going to watch a stand-up on ...</td>\n",
       "      <td>Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenny can't decide which trousers to buy. Bob ...</td>\n",
       "      <td>Lenny: Babe, can you help me with something?\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma will be home soon and she will let Will k...</td>\n",
       "      <td>Will: hey babe, what do you want for dinner to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane is in Warsaw. Ollie and Jane has a party....</td>\n",
       "      <td>Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Benjamin didn't come to see a basketball game ...</td>\n",
       "      <td>Alex: Were you able to attend Friday night's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>The audition starts at 7.30 P.M. in Antena 3.</td>\n",
       "      <td>Jamilla: remember that the audition starts at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Marta sent a file accidentally,</td>\n",
       "      <td>Marta: &lt;file_gif&gt;\\r\\nMarta: Sorry girls, I cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>There was a meet-and-greet with James Charles ...</td>\n",
       "      <td>Cora: Have you heard how much fuss British med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Rachel sends a list of Top 50 films of 2018. J...</td>\n",
       "      <td>Rachel: &lt;file_other&gt;\\r\\nRachel: Top 50 Best Fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary  \\\n",
       "0    Hannah needs Betty's number but Amanda doesn't...   \n",
       "1    Eric and Rob are going to watch a stand-up on ...   \n",
       "2    Lenny can't decide which trousers to buy. Bob ...   \n",
       "3    Emma will be home soon and she will let Will k...   \n",
       "4    Jane is in Warsaw. Ollie and Jane has a party....   \n",
       "..                                                 ...   \n",
       "814  Benjamin didn't come to see a basketball game ...   \n",
       "815      The audition starts at 7.30 P.M. in Antena 3.   \n",
       "816                    Marta sent a file accidentally,   \n",
       "817  There was a meet-and-greet with James Charles ...   \n",
       "818  Rachel sends a list of Top 50 films of 2018. J...   \n",
       "\n",
       "                                              dialogue  \n",
       "0    Hannah: Hey, do you have Betty's number?\\nAman...  \n",
       "1    Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric:...  \n",
       "2    Lenny: Babe, can you help me with something?\\r...  \n",
       "3    Will: hey babe, what do you want for dinner to...  \n",
       "4    Ollie: Hi , are you in Warsaw\\r\\nJane: yes, ju...  \n",
       "..                                                 ...  \n",
       "814  Alex: Were you able to attend Friday night's b...  \n",
       "815  Jamilla: remember that the audition starts at ...  \n",
       "816  Marta: <file_gif>\\r\\nMarta: Sorry girls, I cli...  \n",
       "817  Cora: Have you heard how much fuss British med...  \n",
       "818  Rachel: <file_other>\\r\\nRachel: Top 50 Best Fi...  \n",
       "\n",
       "[819 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(test_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.862743Z",
     "iopub.status.busy": "2023-11-16T16:24:15.862374Z",
     "iopub.status.idle": "2023-11-16T16:24:15.893328Z",
     "shell.execute_reply": "2023-11-16T16:24:15.892294Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.862712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice is checking if Bob has finished the repo...</td>\n",
       "      <td>Alice: Hey, have you finished the report? Bob:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John and Emma discuss a new project, and Emma ...</td>\n",
       "      <td>John: Did you hear about the new project? Emma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike loses his keys, but Sara suggests checkin...</td>\n",
       "      <td>Mike: I can't find my keys anywhere. Sara: Did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam and Sophie confirm their movie plans, wit...</td>\n",
       "      <td>Liam: Are we still on for the movie tonight? S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David and Nina discuss the weather forecast, d...</td>\n",
       "      <td>David: Have you seen the weather forecast for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>Ravi tells Mei about his culinary experiments ...</td>\n",
       "      <td>Ravi: I've been experimenting with cooking dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Sophie discusses her project to clean up the l...</td>\n",
       "      <td>Sophie: I'm working on a project to clean up o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Neil shares his interest in historical novels ...</td>\n",
       "      <td>Neil: I've been exploring historical novels re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Grace mentions her new blog on sustainable liv...</td>\n",
       "      <td>Grace: I started a blog about sustainable livi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Lena talks about learning sign language, and M...</td>\n",
       "      <td>Lena: I've been learning sign language. It's a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary  \\\n",
       "0    Alice is checking if Bob has finished the repo...   \n",
       "1    John and Emma discuss a new project, and Emma ...   \n",
       "2    Mike loses his keys, but Sara suggests checkin...   \n",
       "3    Liam and Sophie confirm their movie plans, wit...   \n",
       "4    David and Nina discuss the weather forecast, d...   \n",
       "..                                                 ...   \n",
       "904  Ravi tells Mei about his culinary experiments ...   \n",
       "905  Sophie discusses her project to clean up the l...   \n",
       "906  Neil shares his interest in historical novels ...   \n",
       "907  Grace mentions her new blog on sustainable liv...   \n",
       "908  Lena talks about learning sign language, and M...   \n",
       "\n",
       "                                              dialogue  \n",
       "0    Alice: Hey, have you finished the report? Bob:...  \n",
       "1    John: Did you hear about the new project? Emma...  \n",
       "2    Mike: I can't find my keys anywhere. Sara: Did...  \n",
       "3    Liam: Are we still on for the movie tonight? S...  \n",
       "4    David: Have you seen the weather forecast for ...  \n",
       "..                                                 ...  \n",
       "904  Ravi: I've been experimenting with cooking dif...  \n",
       "905  Sophie: I'm working on a project to clean up o...  \n",
       "906  Neil: I've been exploring historical novels re...  \n",
       "907  Grace: I started a blog about sustainable livi...  \n",
       "908  Lena: I've been learning sign language. It's a...  \n",
       "\n",
       "[909 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file 'dialogue.txt' in read mode\n",
    "with open('/kaggle/input/chat-conversations-with-summary/dialogue.txt', 'r') as file:\n",
    "    # Read all lines from the file\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over each line in the file\n",
    "for line in lines:\n",
    "    # Strip leading and trailing whitespace and split the line into columns based on '~'\n",
    "    columns = line.strip().split('~')\n",
    "    # Append the processed line to the data list\n",
    "    data.append(columns)\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exclude the first row which might be headers or unwanted data\n",
    "df = df[1:]\n",
    "\n",
    "# Rename the first and second columns to 'dialogue' and 'summary' respectively\n",
    "df.rename(columns={0 : 'dialogue', 1 : 'summary'}, inplace=True)\n",
    "\n",
    "# Reset the index of the DataFrame to make it start from 0\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rearrange the columns so that 'summary' comes first, followed by 'dialogue'\n",
    "df = df[['summary', 'dialogue']]\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have joined Training and Valid sets together to increase the size of training data. We will use test datasets to evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.895073Z",
     "iopub.status.busy": "2023-11-16T16:24:15.894428Z",
     "iopub.status.idle": "2023-11-16T16:24:15.911676Z",
     "shell.execute_reply": "2023-11-16T16:24:15.910500Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.895041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ursula: Hi, Mr. Smith. I'm Doctor Hawkins. Why...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Queenie: Hello Mrs. Parker, how have you been?...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob: Excuse me, did you see a set of keys?\\nSe...</td>\n",
       "      <td>Bob's looking for a set of keys and asks for S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zelda: Why didn't you tell me you had a girlfr...</td>\n",
       "      <td>Zelda's angry because Victor didn't tell Zelda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samuel: Watsup, ladies! Y'll looking'fine toni...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29414</th>\n",
       "      <td>Ravi: I've been experimenting with cooking dif...</td>\n",
       "      <td>Ravi tells Mei about his culinary experiments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29415</th>\n",
       "      <td>Sophie: I'm working on a project to clean up o...</td>\n",
       "      <td>Sophie discusses her project to clean up the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29416</th>\n",
       "      <td>Neil: I've been exploring historical novels re...</td>\n",
       "      <td>Neil shares his interest in historical novels ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29417</th>\n",
       "      <td>Grace: I started a blog about sustainable livi...</td>\n",
       "      <td>Grace mentions her new blog on sustainable liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29418</th>\n",
       "      <td>Lena: I've been learning sign language. It's a...</td>\n",
       "      <td>Lena talks about learning sign language, and M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29419 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dialogue  \\\n",
       "0      Ursula: Hi, Mr. Smith. I'm Doctor Hawkins. Why...   \n",
       "1      Queenie: Hello Mrs. Parker, how have you been?...   \n",
       "2      Bob: Excuse me, did you see a set of keys?\\nSe...   \n",
       "3      Zelda: Why didn't you tell me you had a girlfr...   \n",
       "4      Samuel: Watsup, ladies! Y'll looking'fine toni...   \n",
       "...                                                  ...   \n",
       "29414  Ravi: I've been experimenting with cooking dif...   \n",
       "29415  Sophie: I'm working on a project to clean up o...   \n",
       "29416  Neil: I've been exploring historical novels re...   \n",
       "29417  Grace: I started a blog about sustainable livi...   \n",
       "29418  Lena: I've been learning sign language. It's a...   \n",
       "\n",
       "                                                 summary  \n",
       "0      Mr. Smith's getting a check-up, and Doctor Haw...  \n",
       "1      Mrs Parker takes Ricky for his vaccines. Dr. P...  \n",
       "2      Bob's looking for a set of keys and asks for S...  \n",
       "3      Zelda's angry because Victor didn't tell Zelda...  \n",
       "4      Malik invites Nikki to dance. Nikki agrees if ...  \n",
       "...                                                  ...  \n",
       "29414  Ravi tells Mei about his culinary experiments ...  \n",
       "29415  Sophie discusses her project to clean up the l...  \n",
       "29416  Neil shares his interest in historical novels ...  \n",
       "29417  Grace mentions her new blog on sustainable liv...  \n",
       "29418  Lena talks about learning sign language, and M...  \n",
       "\n",
       "[29419 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the DataFrames\n",
    "train_df = pd.concat([train_df1, train_df2, valid_df1, valid_df2, df])\n",
    "\n",
    "# Reseting the index\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Displaying the result\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.913917Z",
     "iopub.status.busy": "2023-11-16T16:24:15.913103Z",
     "iopub.status.idle": "2023-11-16T16:24:15.925025Z",
     "shell.execute_reply": "2023-11-16T16:24:15.923995Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.913877Z"
    }
   },
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    # Initialize the dataset with a tokenizer, data, and maximum token length\n",
    "    def __init__(self, tokenizer, data, max_length=512):\n",
    "        self.tokenizer = tokenizer  # Tokenizer for encoding text\n",
    "        self.data = data            # Data containing dialogues and summaries\n",
    "        self.max_length = max_length # Maximum length of tokens\n",
    "\n",
    "    # Return the number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Retrieve an item from the dataset by index\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]  # Get the row at the specified index\n",
    "        dialogue = item['dialogue'] # Extract dialogue from the row\n",
    "        summary = item['summary']   # Extract summary from the row\n",
    "\n",
    "        # Encode the dialogue as input data for the model\n",
    "        source = self.tokenizer.encode_plus(\n",
    "            dialogue, \n",
    "            max_length=self.max_length, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt', \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Encode the summary as target data for the model\n",
    "        target = self.tokenizer.encode_plus(\n",
    "            summary, \n",
    "            max_length=self.max_length, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt', \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Return a dictionary containing input_ids, attention_mask, labels, and the original summary text\n",
    "        return {\n",
    "            'input_ids': source['input_ids'].flatten(),\n",
    "            'attention_mask': source['attention_mask'].flatten(),\n",
    "            'labels': target['input_ids'].flatten(),\n",
    "            'summary': summary \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:15.927105Z",
     "iopub.status.busy": "2023-11-16T16:24:15.926279Z",
     "iopub.status.idle": "2023-11-16T16:24:24.205219Z",
     "shell.execute_reply": "2023-11-16T16:24:24.204366Z",
     "shell.execute_reply.started": "2023-11-16T16:24:15.927068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78f0aa609fa481ab39e153caae5f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c1e60aeeda4f26a81d7416c68c9ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf6d6d5fa5548e6bd7eb2d3f069bd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c8759b6e7494799c3094f2dd0507c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241ea7651c8f4bdc9f0abbb747dae173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer for BART\n",
    "# 'facebook/bart-base' is a pretrained model identifier\n",
    "# The tokenizer is responsible for converting text input into tokens that the model can understand\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "# Initialize the BART model for conditional generation\n",
    "# This model is used for tasks like summarization where the output is conditional on the input text\n",
    "# The model is loaded with pretrained weights from 'facebook/bart-base'\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:24.206673Z",
     "iopub.status.busy": "2023-11-16T16:24:24.206371Z",
     "iopub.status.idle": "2023-11-16T16:24:24.211222Z",
     "shell.execute_reply": "2023-11-16T16:24:24.210343Z",
     "shell.execute_reply.started": "2023-11-16T16:24:24.206647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an instance of the SummaryDataset class for training data\n",
    "# It uses the tokenizer to process the training data (train_df) \n",
    "# for model input\n",
    "train_dataset = SummaryDataset(tokenizer, train_df)\n",
    "\n",
    "# Creating an instance of the SummaryDataset class for validation data\n",
    "# It uses the same tokenizer but with a different dataset (test_df2) \n",
    "# for validation purposes\n",
    "valid_dataset = SummaryDataset(tokenizer, test_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:24.212681Z",
     "iopub.status.busy": "2023-11-16T16:24:24.212336Z",
     "iopub.status.idle": "2023-11-16T16:24:24.319417Z",
     "shell.execute_reply": "2023-11-16T16:24:24.318420Z",
     "shell.execute_reply.started": "2023-11-16T16:24:24.212655Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define training arguments for the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Directory to save model output and checkpoints\n",
    "    num_train_epochs=2,              # Number of epochs to train the model\n",
    "    per_device_train_batch_size=8,   # Batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Weight decay for regularization\n",
    "    logging_dir='./logs',            # Directory to save logs\n",
    "    logging_steps=10,                # Log metrics every specified number of steps\n",
    "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
    "    report_to='none'                 # Disables reporting to any online services (e.g., TensorBoard, WandB)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T16:24:24.321034Z",
     "iopub.status.busy": "2023-11-16T16:24:24.320698Z",
     "iopub.status.idle": "2023-11-16T17:58:37.177020Z",
     "shell.execute_reply": "2023-11-16T17:58:37.175977Z",
     "shell.execute_reply.started": "2023-11-16T16:24:24.321006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3678' max='3678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3678/3678 1:33:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.086062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.081724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3678, training_loss=0.4837404892229399, metrics={'train_runtime': 5644.8729, 'train_samples_per_second': 10.423, 'train_steps_per_second': 0.652, 'total_flos': 1.793783686496256e+16, 'train_loss': 0.4837404892229399, 'epoch': 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,             # The model to be trained (e.g., our BART model)\n",
    "    args=training_args,      # Training arguments specifying training parameters like learning rate, batch size, etc.\n",
    "    train_dataset=train_dataset,  # The dataset to be used for training the model\n",
    "    eval_dataset=valid_dataset    # The dataset to be used for evaluating the model during training\n",
    ")\n",
    "\n",
    "# Starting the training process\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Rogue Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:58:37.178920Z",
     "iopub.status.busy": "2023-11-16T17:58:37.178516Z",
     "iopub.status.idle": "2023-11-16T17:59:59.598975Z",
     "shell.execute_reply": "2023-11-16T17:59:59.597908Z",
     "shell.execute_reply.started": "2023-11-16T17:58:37.178884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90172bd1942d49e592513f1a207d2e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.5203167404161397, recall=0.454729290212834, fmeasure=0.4632587632485201), mid=Score(precision=0.5354479435805708, recall=0.46890642945251565, fmeasure=0.47534285466245074), high=Score(precision=0.5502350562403443, recall=0.4824408056039646, fmeasure=0.48742275414871145)), 'rouge2': AggregateScore(low=Score(precision=0.25078879710302293, recall=0.21609817018001448, fmeasure=0.22050781070275272), mid=Score(precision=0.26568774609184886, recall=0.2292050456292191, fmeasure=0.2331994917519589), high=Score(precision=0.2808212845633841, recall=0.24289826444917545, fmeasure=0.24596704167812236)), 'rougeL': AggregateScore(low=Score(precision=0.43189569859182625, recall=0.3784438094396151, fmeasure=0.38432840225294457), mid=Score(precision=0.4465577989373004, recall=0.39079956181403797, fmeasure=0.39648919210982875), high=Score(precision=0.46139814838987636, recall=0.4039602038430952, fmeasure=0.4090468688096221)), 'rougeLsum': AggregateScore(low=Score(precision=0.43240651966225446, recall=0.37708782318853007, fmeasure=0.3830899011510724), mid=Score(precision=0.44632278342320875, recall=0.39037924872253826, fmeasure=0.3960953437919044), high=Score(precision=0.46162203989167455, recall=0.40313163998239104, fmeasure=0.4075494148313833))}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the ROUGE metric for evaluation\n",
    "rouge = load_metric('rouge')\n",
    "\n",
    "def generate_summaries(model, tokenizer, dataset, batch_size=8):\n",
    "    \"\"\"\n",
    "    Generate summaries using the provided model and tokenizer on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        model: The trained summarization model.\n",
    "        tokenizer: Tokenizer associated with the model.\n",
    "        dataset: Dataset for which summaries need to be generated.\n",
    "        batch_size: Number of data samples to process in each batch.\n",
    "\n",
    "    Returns:\n",
    "        summaries: Generated summaries by the model.\n",
    "        references: Actual summaries from the dataset for comparison.\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    summaries = []    # List to store generated summaries\n",
    "    references = []   # List to store actual summaries\n",
    "\n",
    "    # Create a DataLoader for batch processing\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    # Disabled gradient calculations for efficiency\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move input data to the same device as the model\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "\n",
    "            # Generate summaries with the model\n",
    "            outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=2048, num_beams=2)\n",
    "            batch_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "\n",
    "            # Append generated and actual summaries to the respective lists\n",
    "            summaries.extend(batch_summaries)\n",
    "            references.extend(batch['summary'])\n",
    "\n",
    "    return summaries, references\n",
    "\n",
    "# Generate summaries for the validation dataset\n",
    "generated_summaries, actual_summaries = generate_summaries(model, tokenizer, valid_dataset, batch_size=8)\n",
    "\n",
    "# Compute and print the ROUGE score for evaluation\n",
    "rouge_score = rouge.compute(predictions=generated_summaries, references=actual_summaries)\n",
    "print(rouge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Rouge scores to better understand the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:03:51.659121Z",
     "iopub.status.busy": "2023-11-16T18:03:51.658647Z",
     "iopub.status.idle": "2023-11-16T18:03:51.702328Z",
     "shell.execute_reply": "2023-11-16T18:03:51.701251Z",
     "shell.execute_reply.started": "2023-11-16T18:03:51.659089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rouge1</th>\n",
       "      <th>low</th>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>0.4632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>0.5354</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.4874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rouge2</th>\n",
       "      <th>low</th>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>0.2656</td>\n",
       "      <td>0.2292</td>\n",
       "      <td>0.2331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.2459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rougeL</th>\n",
       "      <th>low</th>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rougeLsum</th>\n",
       "      <th>low</th>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>0.4075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall  F-Measure\n",
       "rouge1    low      0.5203  0.4547     0.4632\n",
       "          mid      0.5354  0.4689     0.4753\n",
       "          high     0.5502  0.4824     0.4874\n",
       "rouge2    low      0.2507  0.2160     0.2205\n",
       "          mid      0.2656  0.2292     0.2331\n",
       "          high     0.2808  0.2428     0.2459\n",
       "rougeL    low      0.4318  0.3784     0.3843\n",
       "          mid      0.4465  0.3907     0.3964\n",
       "          high     0.4613  0.4039     0.4090\n",
       "rougeLsum low      0.4324  0.3770     0.3830\n",
       "          mid      0.4463  0.3903     0.3960\n",
       "          high     0.4616  0.4031     0.4075"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores = {\n",
    "    'rouge1': {\n",
    "        'low': {'precision': 0.5203, 'recall': 0.4547, 'fmeasure': 0.4632},\n",
    "        'mid': {'precision': 0.5354, 'recall': 0.4689, 'fmeasure': 0.4753},\n",
    "        'high': {'precision': 0.5502, 'recall': 0.4824, 'fmeasure': 0.4874}\n",
    "    },\n",
    "    'rouge2': {\n",
    "        'low': {'precision': 0.2507, 'recall': 0.2160, 'fmeasure': 0.2205},\n",
    "        'mid': {'precision': 0.2656, 'recall': 0.2292, 'fmeasure': 0.2331},\n",
    "        'high': {'precision': 0.2808, 'recall': 0.2428, 'fmeasure': 0.2459}\n",
    "    },\n",
    "    'rougeL': {\n",
    "        'low': {'precision': 0.4318, 'recall': 0.3784, 'fmeasure': 0.3843},\n",
    "        'mid': {'precision': 0.4465, 'recall': 0.3907, 'fmeasure': 0.3964},\n",
    "        'high': {'precision': 0.4613, 'recall': 0.4039, 'fmeasure': 0.4090}\n",
    "    },\n",
    "    'rougeLsum': {\n",
    "        'low': {'precision': 0.4324, 'recall': 0.3770, 'fmeasure': 0.3830},\n",
    "        'mid': {'precision': 0.4463, 'recall': 0.3903, 'fmeasure': 0.3960},\n",
    "        'high': {'precision': 0.4616, 'recall': 0.4031, 'fmeasure': 0.4075}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the nested dictionary into a Pandas DataFrame\n",
    "scores = pd.DataFrame.from_dict({(i, j): rouge_scores[i][j] \n",
    "                            for i in rouge_scores.keys() \n",
    "                            for j in rouge_scores[i].keys()},\n",
    "                            orient='index')\n",
    "\n",
    "# Set column names for readability\n",
    "scores.columns = ['Precision', 'Recall', 'F-Measure']\n",
    "\n",
    "# Display the DataFrame\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test the model on a conversation using input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:04:03.078869Z",
     "iopub.status.busy": "2023-11-16T18:04:03.078461Z",
     "iopub.status.idle": "2023-11-16T18:04:03.089470Z",
     "shell.execute_reply": "2023-11-16T18:04:03.088511Z",
     "shell.execute_reply.started": "2023-11-16T18:04:03.078826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU support) is available and choose the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:04:05.870343Z",
     "iopub.status.busy": "2023-11-16T18:04:05.869492Z",
     "iopub.status.idle": "2023-11-16T18:04:05.876427Z",
     "shell.execute_reply": "2023-11-16T18:04:05.875524Z",
     "shell.execute_reply.started": "2023-11-16T18:04:05.870307Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_text(text, max_length=5000):\n",
    "    \"\"\"\n",
    "    Generates a summary for the given text using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be summarized.\n",
    "        max_length (int): The maximum length of the input text for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary of the input text.\n",
    "    \"\"\"\n",
    "    # Encode the input text using the tokenizer. The 'pt' indicates PyTorch tensors.\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=max_length, truncation=False)\n",
    "    \n",
    "    # Move the encoded text to the same device as the model (e.g., GPU or CPU)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Generate summary IDs with the model. num_beams controls the beam search width.\n",
    "    # early_stopping is set to False for a thorough search, though it can be set to True for faster results.\n",
    "    summary_ids = model.generate(inputs, max_length=2000, num_beams=30, early_stopping=False)\n",
    "\n",
    "    # Decode the generated IDs back to text, skipping special tokens like padding or EOS.\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Return the generated summary\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T18:24:48.340326Z",
     "iopub.status.busy": "2023-11-16T18:24:48.339528Z",
     "iopub.status.idle": "2023-11-16T18:24:50.922034Z",
     "shell.execute_reply": "2023-11-16T18:24:50.921055Z",
     "shell.execute_reply.started": "2023-11-16T18:24:48.340291Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text:  Web Developer (You): Hey, I just launched a new website with some exciting features. Would you like to check it out? Machine Learning Enthusiast: That sounds interesting! I'd love to see how you've integrated machine learning into it. Computer Science Student: Speaking of machine learning, have you heard about the latest breakthroughs in natural language processing? Science Enthusiast: Yes, I've been following those developments closely. It's amazing how AI is transforming language understanding. Mathematics Enthusiast: Absolutely! The mathematical foundations of deep learning play a crucial role in these advancements. News Enthusiast: By the way, did you catch the latest headlines? There's a lot happening in the world right now. Web Developer (You): I did! In fact, my website can recommend personalized news articles based on user preferences. Clinical Medical Assistant: That's impressive! Speaking of recommendations, have you worked on any projects related to healthcare? Machine Learning Enthusiast: Yes, I did a project on hybrid acoustic and facial emotion recognition, which could have applications in mental health. Computer Science Student: That's fascinating! It's incredible how our interests and expertise intersect across various fields of study and technology.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text: Web Developer (You): Hey, I just launched a new website with some exciting features. Would you like to check it out? Machine Learning Enthusiast: That sounds interesting! I'd love to see how you've integrated machine learning into it. Computer Science Student: Speaking of machine learning, have you heard about the latest breakthroughs in natural language processing? Science Enthusiast: Yes, I've been following those developments closely. It's amazing how AI is transforming language understanding. Mathematics Enthusiast: Absolutely! The mathematical foundations of deep learning play a crucial role in these advancements. News Enthusiast: By the way, did you catch the latest headlines? There's a lot happening in the world right now. Web Developer (You): I did! In fact, my website can recommend personalized news articles based on user preferences. Clinical Medical Assistant: That's impressive! Speaking of recommendations, have you worked on any projects related to healthcare? Machine Learning Enthusiast: Yes, I did a project on hybrid acoustic and facial emotion recognition, which could have applications in mental health. Computer Science Student: That's fascinating! It's incredible how our interests and expertise intersect across various fields of study and technology.\n",
      "\n",
      "Web Developer introduces his new website to Computer Science Student, who is interested in the latest breakthroughs in natural language processing. Science Enthusiast thinks it's amazing how their interests and expertise intersect across various fields of study and technology.\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to enter text for summarization\n",
    "text = input('Enter the text: ')\n",
    "print()\n",
    "\n",
    "# Call the summarize_text function to generate a summary of the input text\n",
    "summary = summarize_text(text)\n",
    "\n",
    "# Print the generated summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, I fine-tuned the BART Base model for summarizing chat conversations. The model showed promising performance, especially in capturing the essence of dialogues. The findings revealed the model's strengths and areas of improvement as follows:\n",
    "\n",
    "1. **Consistency in Capturing Key Points:** The ROUGE-1 scores, with a high precision of 0.5502 and recall of 0.4824, indicate that the model is consistently capturing key points from the conversations. This suggests that for most of the chat content, the generated summaries were aligned well with the essential topics.\n",
    "\n",
    "\n",
    "2. **Complex Relationships and Nuances:** The ROUGE-2 scores, particularly the high precision of 0.2808 and recall of 0.2428, reflect the model's ability to grasp more complex relationships and nuances in the conversations. While lower than ROUGE-1, these scores are indicative of the model's potential in understanding subtleties in dialogues.\n",
    "\n",
    "\n",
    "3. **Summary Length and Relevance:** The ROUGE-L and ROUGE-Lsum scores, with a high precision of around 0.4613 and a recall of approximately 0.4039, demonstrate the model's capability in maintaining the length and relevance of the original dialogues in the summaries.\n",
    "\n",
    "\n",
    "\n",
    "- While the model shows effectiveness in summarizing chat conversations, there is room for improvement, particularly in capturing more intricate details and subtleties, as suggested by the ROUGE-2 scores.\n",
    "\n",
    "I welcome any feedback or questions in the comments and am open to collaborations on similar projects. For further discussions or networking opportunities, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/farneet-singh-6b155b208/)."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3995670,
     "sourceId": 6956480,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005809,
     "sourceId": 6971920,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4008786,
     "sourceId": 6976321,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "my_new_kernel",
   "language": "python",
   "name": "my_new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
